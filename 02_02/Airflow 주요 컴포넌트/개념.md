# DAG란?
- Airflow에서 작업(Task)들의 실행 순서를 정의하는 그래프
- 방향성(Directed) -> 작업이 정해진 순서로 실행 됨
- 비순환(Acyclic) -> 순환(Loop) 구조가 없어서 무한 실행 방지

# Task란?
- Task는 워크플로우를 구성하는 개별 작업 단위
- ETL, 데이터 변환, 머신러닝 모델 실행, 파일 이동 등의 작업을 수행할 수 있음
- 워크플로우를 구성하는 기본 요소

# Airflow 주요 컴포넌트
- Scheduler -> DAG 실행 스케줄 관리
- Executor -> 테스크 실행 방식(Local, Celery, Kubernetes)
- Worker -> 실제 태스크 실행하는 프로세스
- Metadata Database -> DAG 실행 정보 저장
- Web UI -> DAG 및 태스크 상태 모니터링

# Dag Directory
- 파이썬으로 작성된 DAG 파일을 저장하는 공간
- dag_foler, dags_folde라고 불림
- 기본적으로 $AIRFLOW/dags/로 설정되어 있음
- DAG를 작성한 후 DAG Directory에 저장하면, Airflow Seheduler가 주기적으로 DAG Directory를 스캔한 후 DAG를 파싱함

# Scheduler
- DAG 파일을 파싱하고, Task 및 DAG를 모니터링하며 실행을 스케줄링하는 핵심 컴포넌트
- DAG Run과 Task Instance 상태를 관리하고 Executor에게 실행을 요청하는 역할 수행
- DAG 파일 처리 과정
    1. DAG 파일 검색 및 로드
    2. DAG 파일 파싱 및 해석
    3. DAG 등록 및 실행 준비

# Executor
- Executor는 Scheduler에서 생성하는 서브 프로세스
- Queue에 들어온 Task Instance를 실제로 실행하는 역할
    - 단일 프로세스형(Single-Process)
        - Sequential Executor : 한 번에 하나의 Task만 순차적으로 실행하며, 개발.테스트용으로 사용됨
    - 로컬 병렬형(Local Multi-Process)
        - Local Executor : Scheduler 내부에서 여러 Task를 병렬로 실행 할 수 있음(멀티프로세싱 기반)
    - 분산형(Distributed)
        - Celery Executor : 여러 워커 노드에 Task를 분산 실행하며, 대규모 분산 환경에 적합함
        - Kubernetes Executor : 각 Task를 독립적인 Pod로 실행하여 완전한 격리와 자동 확장을 지원

# Meta Database
- Airflow의 DAG, DAG Run, Task Instance, Variables, Connections 등 여러 컴포넌트에서 사용해야하는 데이터를 저장함

# Webserver
- Webserver는 Meta Database와 통신하며 DAG, DAG Run, Task Instance, Variables, Connections 등의 데이터를 가져와 웹에서 보여주고 유저와 상호작용할 수 있게 함
