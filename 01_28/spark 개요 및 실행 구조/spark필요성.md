# 데이터 처리의 필요성 증가
- 배치 처리
- 스트림 처리

# 단일 서버의 확장성 부족
- 기존 데이터 처리는 주로 단일 서버로 이루어짐
- 데이터가 증가하면 서버 성능을 높이는 방식(수직 확장, Scale-Up)을 사용
- 그러나 단일 서버는 하드웨어의 물리적 한계로 인해 무한정 성능을 높일 수 없음

# 디스크 기반 처리로 인한 속도 문제
- Spark 이전의 기술은 데이터를 처리할 때 디스크 기반의 저장장치를 사용
- 디스크는 메모리(RAM)보다 데이터 읽기/쓰기 속도가 현저히 느리기 때문에 데이터 처리 과정에서 속도 저하 현상이 발생